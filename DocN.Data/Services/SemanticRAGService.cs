using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;
using Microsoft.SemanticKernel.Agents;
using Microsoft.SemanticKernel.Agents.Chat;
using Microsoft.Extensions.Logging;
using Microsoft.EntityFrameworkCore;
using DocN.Data.Models;
using DocN.Core.Interfaces;
using System.Text;

#pragma warning disable SKEXP0110 // Agents are experimental
#pragma warning disable SKEXP0001 // Type is for evaluation purposes only

namespace DocN.Data.Services;

/// <summary>
/// Advanced RAG service using Microsoft Semantic Kernel and Agent Framework
/// Implements vector-based retrieval and intelligent chat on uploaded documents
/// </summary>
public class SemanticRAGService : ISemanticRAGService
{
    private readonly Kernel _kernel;
    private readonly ApplicationDbContext _context;
    private readonly ILogger<SemanticRAGService> _logger;
    private readonly IEmbeddingService _embeddingService;
    private readonly IChatCompletionService? _chatService;
    private readonly ICacheService _cacheService;

    // Semantic Kernel Agents for RAG pipeline
    private ChatCompletionAgent? _retrievalAgent;
    private ChatCompletionAgent? _synthesisAgent;
    private AgentGroupChat? _agentChat;

    // Constants for vector search optimization
    private const int CandidateLimitMultiplier = 10; // Get 10x topK candidates for better results
    private const int MinCandidateLimit = 100; // Always get at least 100 candidates
    private const int VectorDimension = 1536; // Text-embedding-ada-002 dimension (or compatible models)

    public SemanticRAGService(
        Kernel kernel,
        ApplicationDbContext context,
        ILogger<SemanticRAGService> logger,
        IEmbeddingService embeddingService,
        ICacheService cacheService)
    {
        _kernel = kernel;
        _context = context;
        _logger = logger;
        _embeddingService = embeddingService;
        _cacheService = cacheService;
        
        // Attempt to initialize chat service and agents during construction
        // If initialization fails (e.g., due to missing AI configuration),
        // the service will return appropriate error messages when called
        try
        {
            _chatService = kernel.GetRequiredService<IChatCompletionService>();
            InitializeAgents();
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Could not initialize SemanticRAGService during construction. AI features will be unavailable.");
        }
    }

    /// <summary>
    /// Initialize Semantic Kernel agents for RAG workflow
    /// </summary>
    private void InitializeAgents()
    {
        try
        {
            // Create Retrieval Agent - responsible for finding relevant documents
            _retrievalAgent = new ChatCompletionAgent
            {
                Name = "RetrievalAgent",
                Instructions = @"You are a specialized retrieval agent. Your role is to:
1. Understand the user's query intent
2. Identify key concepts and entities
3. Determine which documents are most relevant
4. Extract the most pertinent information from documents
5. Provide structured information to the synthesis agent

Always be precise and focus on relevance.",
                Kernel = _kernel
            };

            // Create Synthesis Agent - responsible for generating natural language answers
            _synthesisAgent = new ChatCompletionAgent
            {
                Name = "SynthesisAgent",
                Instructions = @"You are an expert synthesis agent. Your role is to:
1. Analyze information provided by the retrieval agent
2. Generate clear, accurate, and natural language answers
3. Cite sources appropriately using document references
4. Maintain conversation context and coherence
5. Be concise yet comprehensive

Always cite your sources using [Document N] format where N is the document number.",
                Kernel = _kernel
            };

            _logger.LogInformation("Semantic Kernel agents initialized successfully");
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error initializing Semantic Kernel agents");
        }
    }

    /// <inheritdoc/>
    public async Task<SemanticRAGResponse> GenerateResponseAsync(
        string query,
        string userId,
        int? conversationId = null,
        List<int>? specificDocumentIds = null,
        int topK = 5)
    {
        var stopwatch = System.Diagnostics.Stopwatch.StartNew();

        try
        {
            // Ensure services are initialized
            if (_chatService == null)
            {
                _logger.LogError("SemanticRAGService is not properly initialized. Chat completion service is not available.");
                return new SemanticRAGResponse
                {
                    Answer = "AI services are not properly configured. Please check the configuration and try again.",
                    SourceDocuments = new List<RelevantDocumentResult>(),
                    ResponseTimeMs = stopwatch.ElapsedMilliseconds,
                    Metadata = new Dictionary<string, object> { { "error", "Service not initialized" } }
                };
            }

            _logger.LogInformation(
                "Generating RAG response for query: {Query}, User: {UserId}, Conversation: {ConvId}",
                query, userId, conversationId);

            // Check cache first (disabled for now - use specific embedding cache if needed)
            // var cacheKey = $"rag:{userId}:{query}:{string.Join(",", specificDocumentIds ?? new List<int>())}";
            // Can add generic caching later if needed

            // Step 1: Vector-based document retrieval
            var relevantDocs = await SearchDocumentsAsync(query, userId, topK, 0.7);

            if (!relevantDocs.Any())
            {
                _logger.LogWarning("No relevant documents found for query: {Query}", query);
                return new SemanticRAGResponse
                {
                    Answer = "I couldn't find any relevant documents to answer your question. Please try rephrasing or upload more documents.",
                    SourceDocuments = new List<RelevantDocumentResult>(),
                    ResponseTimeMs = stopwatch.ElapsedMilliseconds
                };
            }

            // Step 2: Load conversation history
            var conversationHistory = await LoadConversationHistoryAsync(conversationId);

            // Step 3: Build context from relevant documents
            var documentContext = BuildDocumentContext(relevantDocs);

            // Step 4: Generate response using Semantic Kernel
            var answer = await GenerateAnswerWithSemanticKernelAsync(
                query,
                documentContext,
                conversationHistory);

            // Step 5: Save conversation
            var savedConversationId = await SaveConversationAsync(
                conversationId,
                userId,
                query,
                answer,
                relevantDocs.Select(d => d.DocumentId).ToList());

            stopwatch.Stop();

            var response = new SemanticRAGResponse
            {
                Answer = answer,
                SourceDocuments = relevantDocs,
                ConversationId = savedConversationId,
                ResponseTimeMs = stopwatch.ElapsedMilliseconds,
                FromCache = false,
                Metadata = new Dictionary<string, object>
                {
                    ["documentsRetrieved"] = relevantDocs.Count,
                    ["topSimilarityScore"] = relevantDocs.FirstOrDefault()?.SimilarityScore ?? 0,
                    ["hasConversationHistory"] = conversationHistory.Any()
                }
            };

            // Cache disabled for now - can be added with generic caching service later
            // await _cacheService.SetAsync(cacheKey, response, TimeSpan.FromMinutes(5));

            _logger.LogInformation(
                "RAG response generated in {ElapsedMs}ms with {DocCount} documents",
                stopwatch.ElapsedMilliseconds, relevantDocs.Count);

            return response;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error generating RAG response for query: {Query}", query);
            return new SemanticRAGResponse
            {
                Answer = $"An error occurred while processing your request: {ex.Message}",
                ResponseTimeMs = stopwatch.ElapsedMilliseconds
            };
        }
    }

    /// <inheritdoc/>
    public async IAsyncEnumerable<string> GenerateStreamingResponseAsync(
        string query,
        string userId,
        int? conversationId = null,
        List<int>? specificDocumentIds = null)
    {
        // Ensure services are initialized
        if (_chatService == null)
        {
            _logger.LogError("SemanticRAGService is not properly initialized. Chat completion service is not available.");
            yield return "AI services are not properly configured. Please check the configuration and try again.";
            yield break;
        }

        _logger.LogInformation("Generating streaming RAG response for query: {Query}", query);

        // Step 1: Retrieve relevant documents
        var relevantDocs = await SearchDocumentsAsync(query, userId, 5, 0.7);

        if (!relevantDocs.Any())
        {
            yield return "I couldn't find any relevant documents to answer your question.";
            yield break;
        }

        // Step 2: Build context
        var documentContext = BuildDocumentContext(relevantDocs);
        var conversationHistory = await LoadConversationHistoryAsync(conversationId);

        // Step 3: Create chat history
        var chatHistory = new ChatHistory();
        chatHistory.AddSystemMessage(CreateSystemPrompt());
        chatHistory.AddSystemMessage($"DOCUMENT CONTEXT:\n{documentContext}");

        foreach (var msg in conversationHistory)
        {
            if (msg.Role == "user")
                chatHistory.AddUserMessage(msg.Content);
            else if (msg.Role == "assistant")
                chatHistory.AddAssistantMessage(msg.Content);
        }

        chatHistory.AddUserMessage(query);

        // Step 4: Stream the response
        var settings = new OpenAIPromptExecutionSettings
        {
            MaxTokens = 2000,
            Temperature = 0.7,
            TopP = 0.9
        };

        var fullAnswer = new StringBuilder();

        await foreach (var chunk in _chatService.GetStreamingChatMessageContentsAsync(
            chatHistory, settings, _kernel))
        {
            if (!string.IsNullOrEmpty(chunk.Content))
            {
                fullAnswer.Append(chunk.Content);
                yield return chunk.Content;
            }
        }

        // Save conversation after streaming completes
        await SaveConversationAsync(
            conversationId,
            userId,
            query,
            fullAnswer.ToString(),
            relevantDocs.Select(d => d.DocumentId).ToList());
    }

    /// <inheritdoc/>
    public async Task<List<RelevantDocumentResult>> SearchDocumentsAsync(
        string query,
        string userId,
        int topK = 10,
        double minSimilarity = 0.7)
    {
        try
        {
            _logger.LogDebug("Searching documents with vector embeddings for: {Query}", query);

            // Generate query embedding
            var queryEmbedding = await _embeddingService.GenerateEmbeddingAsync(query);
            if (queryEmbedding == null)
            {
                _logger.LogWarning("Failed to generate query embedding");
                return new List<RelevantDocumentResult>();
            }

            // Use database-level vector search instead of in-memory calculation
            return await SearchDocumentsWithEmbeddingDatabaseAsync(queryEmbedding, userId, topK, minSimilarity);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error searching documents for query: {Query}", query);
            return new List<RelevantDocumentResult>();
        }
    }

    /// <summary>
    /// Esegue ricerca documenti utilizzando calcolo di similarità vettoriale ottimizzato a livello database
    /// Utilizza VECTOR_DISTANCE di SQL Server 2025 quando disponibile, altrimenti calcolo in-memory ottimizzato
    /// </summary>
    /// <param name="queryEmbedding">Vettore embedding della query</param>
    /// <param name="userId">ID utente per controllo accesso</param>
    /// <param name="topK">Numero massimo di risultati da restituire</param>
    /// <param name="minSimilarity">Soglia minima di similarità (0-1)</param>
    /// <returns>Lista di documenti rilevanti ordinati per similarità</returns>
    /// <remarks>
    /// Strategia di ottimizzazione:
    /// 1. Tenta di usare VECTOR_DISTANCE nativo di SQL Server 2025 per prestazioni ottimali
    /// 2. Se non disponibile, usa approccio ottimizzato che limita i candidati al database
    /// 3. Recupera solo i documenti più recenti (candidateLimit) per ridurre carico memoria
    /// 4. Combina risultati a livello documento e chunk, prioritizzando i chunk più specifici
    /// </remarks>
    private async Task<List<RelevantDocumentResult>> SearchDocumentsWithEmbeddingDatabaseAsync(
        float[] queryEmbedding,
        string userId,
        int topK = 10,
        double minSimilarity = 0.7)
    {
        try
        {
            _logger.LogDebug("Performing database-optimized vector search for user: {UserId}", userId);

            // Check if we're using SQL Server (vs in-memory database for testing)
            var isSqlServer = _context.Database.IsSqlServer();
            
            if (!isSqlServer)
            {
                _logger.LogDebug("Not using SQL Server, falling back to full in-memory search");
                return await SearchDocumentsWithEmbeddingAsync(queryEmbedding, userId, topK, minSimilarity);
            }

            // Try to use SQL Server VECTOR_DISTANCE if available (SQL Server 2025+)
            try
            {
                return await SearchWithVectorDistanceAsync(queryEmbedding, userId, topK, minSimilarity);
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "VECTOR_DISTANCE not available, using optimized in-memory calculation");
                // Fall through to optimized in-memory approach
            }

            // Optimized approach: Limit candidate set at database level before in-memory calculation
            // This significantly reduces memory usage and computation compared to loading ALL documents
            
            var candidateLimit = Math.Max(topK * CandidateLimitMultiplier, MinCandidateLimit); // Get reasonable number of candidates
            
            // Get recent documents with embeddings (most recent are often most relevant)
            // Query the actual mapped fields: EmbeddingVector768 or EmbeddingVector1536
            var documents = await _context.Documents
                .Where(d => d.OwnerId == userId && (d.EmbeddingVector768 != null || d.EmbeddingVector1536 != null))
                .OrderByDescending(d => d.UploadedAt)
                .Take(candidateLimit)
                .Select(d => new { d.Id, d.FileName, d.ActualCategory, d.ExtractedText, d.EmbeddingVector768, d.EmbeddingVector1536 })
                .ToListAsync();

            _logger.LogDebug("Retrieved {Count} candidate documents for similarity calculation", documents.Count);

            // Calculate similarity scores for documents
            var scoredDocs = new List<(int id, string fileName, string? category, string? text, double score)>();
            foreach (var doc in documents)
            {
                // Use the populated vector field
                var docEmbedding = doc.EmbeddingVector768 ?? doc.EmbeddingVector1536;
                if (docEmbedding == null) continue;

                var similarity = CalculateCosineSimilarity(queryEmbedding, docEmbedding);
                if (similarity >= minSimilarity)
                {
                    scoredDocs.Add((doc.Id, doc.FileName, doc.ActualCategory, doc.ExtractedText, similarity));
                }
            }

            // Get recent chunks with embeddings
            // Query the actual mapped fields: ChunkEmbedding768 or ChunkEmbedding1536
            var chunks = await _context.DocumentChunks
                .Include(c => c.Document)
                .Where(c => c.Document!.OwnerId == userId && (c.ChunkEmbedding768 != null || c.ChunkEmbedding1536 != null))
                .OrderByDescending(c => c.CreatedAt)
                .Take(candidateLimit)
                .Select(c => new { 
                    c.DocumentId, 
                    c.Document!.FileName, 
                    c.Document.ActualCategory, 
                    c.ChunkText, 
                    c.ChunkIndex, 
                    c.ChunkEmbedding768,
                    c.ChunkEmbedding1536
                })
                .ToListAsync();

            _logger.LogDebug("Retrieved {Count} candidate chunks for similarity calculation", chunks.Count);

            // Calculate similarity scores for chunks
            var scoredChunks = new List<(int docId, string fileName, string? category, string chunkText, int chunkIndex, double score)>();
            foreach (var chunk in chunks)
            {
                // Use the populated vector field
                var chunkEmbedding = chunk.ChunkEmbedding768 ?? chunk.ChunkEmbedding1536;
                if (chunkEmbedding == null) continue;

                var similarity = CalculateCosineSimilarity(queryEmbedding, chunkEmbedding);
                if (similarity >= minSimilarity)
                {
                    scoredChunks.Add((chunk.DocumentId, chunk.FileName, chunk.ActualCategory, chunk.ChunkText, chunk.ChunkIndex, similarity));
                }
            }

            // Combine results - prioritize chunks over full documents
            var results = new List<RelevantDocumentResult>();

            // Add chunk-based results (higher priority due to more granular matching)
            foreach (var (docId, fileName, category, chunkText, chunkIndex, score) in scoredChunks.OrderByDescending(x => x.score).Take(topK))
            {
                results.Add(new RelevantDocumentResult
                {
                    DocumentId = docId,
                    FileName = fileName,
                    Category = category,
                    SimilarityScore = score,
                    RelevantChunk = chunkText,
                    ChunkIndex = chunkIndex
                });
            }

            // Add document-level results if we don't have enough chunks
            if (results.Count < topK)
            {
                var existingDocIds = new HashSet<int>(results.Select(r => r.DocumentId));
                foreach (var (id, fileName, category, text, score) in scoredDocs.OrderByDescending(x => x.score))
                {
                    if (existingDocIds.Contains(id))
                        continue;

                    results.Add(new RelevantDocumentResult
                    {
                        DocumentId = id,
                        FileName = fileName,
                        Category = category,
                        SimilarityScore = score,
                        ExtractedText = text
                    });
                    
                    existingDocIds.Add(id);
                    
                    if (results.Count >= topK)
                        break;
                }
            }

            _logger.LogInformation("Database-optimized search: processed {DocCount} docs + {ChunkCount} chunks, found {ResultCount} results above {MinSim:P0} threshold", 
                documents.Count, chunks.Count, results.Count, minSimilarity);
            return results.Take(topK).ToList();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error in database-optimized vector search, falling back to full in-memory");
            return await SearchDocumentsWithEmbeddingAsync(queryEmbedding, userId, topK, minSimilarity);
        }
    }

    /// <summary>
    /// Esegue ricerca vettoriale utilizzando la funzione VECTOR_DISTANCE di SQL Server 2025
    /// Fornisce calcolo di similarità vettoriale a livello database per prestazioni ottimali
    /// </summary>
    /// <param name="queryEmbedding">Vettore embedding della query</param>
    /// <param name="userId">ID utente per filtro di accesso</param>
    /// <param name="topK">Numero massimo di risultati da restituire</param>
    /// <param name="minSimilarity">Soglia minima di similarità (0-1)</param>
    /// <returns>Lista di documenti rilevanti ordinati per similarità decrescente</returns>
    /// <remarks>
    /// Questa funzione richiede SQL Server 2025 con supporto nativo per il tipo VECTOR.
    /// Esegue ricerca sia a livello di documento che di chunk, dando priorità ai chunk più specifici.
    /// </remarks>
    private async Task<List<RelevantDocumentResult>> SearchWithVectorDistanceAsync(
        float[] queryEmbedding,
        string userId,
        int topK = 10,
        double minSimilarity = 0.7)
    {
        // Serialize query embedding to JSON format (required for VECTOR type)
        var embeddingJson = System.Text.Json.JsonSerializer.Serialize(queryEmbedding);

        // Use raw SQL with VECTOR_DISTANCE function for document-level search
        // Note: This requires SQL Server 2025 with VECTOR type support
        var sql = $@"
            WITH DocumentScores AS (
                SELECT TOP (@topK)
                    d.Id,
                    d.FileName,
                    d.ActualCategory,
                    d.ExtractedText,
                    CAST(VECTOR_DISTANCE('cosine', d.EmbeddingVector, CAST(@queryEmbedding AS VECTOR({VectorDimension}))) AS FLOAT) AS SimilarityScore
                FROM Documents d
                WHERE d.OwnerId = @userId
                    AND d.EmbeddingVector IS NOT NULL
                    AND VECTOR_DISTANCE('cosine', d.EmbeddingVector, CAST(@queryEmbedding AS VECTOR({VectorDimension}))) >= @minSimilarity
                ORDER BY SimilarityScore DESC
            ),
            ChunkScores AS (
                SELECT TOP (@topK)
                    dc.DocumentId AS Id,
                    d.FileName,
                    d.ActualCategory,
                    dc.ChunkText,
                    dc.ChunkIndex,
                    CAST(VECTOR_DISTANCE('cosine', dc.ChunkEmbedding, CAST(@queryEmbedding AS VECTOR({VectorDimension}))) AS FLOAT) AS SimilarityScore
                FROM DocumentChunks dc
                INNER JOIN Documents d ON dc.DocumentId = d.Id
                WHERE d.OwnerId = @userId
                    AND dc.ChunkEmbedding IS NOT NULL
                    AND VECTOR_DISTANCE('cosine', dc.ChunkEmbedding, CAST(@queryEmbedding AS VECTOR({VectorDimension}))) >= @minSimilarity
                ORDER BY SimilarityScore DESC
            )
            SELECT 
                Id, 
                FileName, 
                ActualCategory, 
                CAST(NULL AS NVARCHAR(MAX)) AS ExtractedText, 
                ChunkText, 
                ChunkIndex, 
                SimilarityScore,
                'CHUNK' AS SourceType
            FROM ChunkScores
            UNION ALL
            SELECT 
                Id, 
                FileName, 
                ActualCategory, 
                ExtractedText, 
                CAST(NULL AS NVARCHAR(MAX)) AS ChunkText, 
                CAST(NULL AS INT) AS ChunkIndex, 
                SimilarityScore,
                'DOCUMENT' AS SourceType
            FROM DocumentScores
            ORDER BY SimilarityScore DESC";

        // Execute the query
        using var command = _context.Database.GetDbConnection().CreateCommand();
        command.CommandText = sql;
        
        var embeddingParam = command.CreateParameter();
        embeddingParam.ParameterName = "@queryEmbedding";
        embeddingParam.Value = embeddingJson;
        command.Parameters.Add(embeddingParam);
        
        var userIdParam = command.CreateParameter();
        userIdParam.ParameterName = "@userId";
        userIdParam.Value = userId;
        command.Parameters.Add(userIdParam);
        
        var topKParam = command.CreateParameter();
        topKParam.ParameterName = "@topK";
        topKParam.Value = topK * CandidateLimitMultiplier; // Get more candidates for merging
        command.Parameters.Add(topKParam);
        
        var minSimParam = command.CreateParameter();
        minSimParam.ParameterName = "@minSimilarity";
        minSimParam.Value = minSimilarity;
        command.Parameters.Add(minSimParam);

        await _context.Database.OpenConnectionAsync();

        var results = new List<RelevantDocumentResult>();
        var existingDocIds = new HashSet<int>();

        using var reader = await command.ExecuteReaderAsync();
        while (await reader.ReadAsync())
        {
            var id = reader.GetInt32(0);
            var fileName = reader.GetString(1);
            var category = reader.IsDBNull(2) ? null : reader.GetString(2);
            var extractedText = reader.IsDBNull(3) ? null : reader.GetString(3);
            var chunkText = reader.IsDBNull(4) ? null : reader.GetString(4);
            var chunkIndex = reader.IsDBNull(5) ? (int?)null : reader.GetInt32(5);
            var score = reader.GetDouble(6);
            var sourceType = reader.GetString(7);

            // Prioritize chunks, avoid duplicate documents
            if (sourceType == "CHUNK" || !existingDocIds.Contains(id))
            {
                results.Add(new RelevantDocumentResult
                {
                    DocumentId = id,
                    FileName = fileName,
                    Category = category,
                    SimilarityScore = score,
                    RelevantChunk = chunkText,
                    ChunkIndex = chunkIndex,
                    ExtractedText = extractedText
                });
                
                if (sourceType == "DOCUMENT")
                    existingDocIds.Add(id);

                if (results.Count >= topK)
                    break;
            }
        }

        _logger.LogInformation("VECTOR_DISTANCE search found {Count} results", results.Count);
        return results;
    }

    /// <inheritdoc/>
    public async Task<List<RelevantDocumentResult>> SearchDocumentsWithEmbeddingAsync(
        float[] queryEmbedding,
        string userId,
        int topK = 10,
        double minSimilarity = 0.7)
    {
        try
        {
            _logger.LogDebug("Searching documents with pre-generated embedding for user: {UserId}", userId);

            if (queryEmbedding == null || queryEmbedding.Length == 0)
            {
                _logger.LogWarning("Query embedding is null or empty");
                return new List<RelevantDocumentResult>();
            }

            // Get all documents with embeddings for the user
            // Query the actual mapped fields: EmbeddingVector768 or EmbeddingVector1536
            var documents = await _context.Documents
                .Where(d => d.OwnerId == userId && (d.EmbeddingVector768 != null || d.EmbeddingVector1536 != null))
                .ToListAsync();

            _logger.LogInformation("=== SIMILARITY SEARCH DEBUG ===");
            _logger.LogInformation("Found {Count} documents with embeddings for user {UserId}", documents.Count, userId);
            _logger.LogInformation("Minimum similarity threshold: {Threshold:P0}", minSimilarity);
            
            // Log query embedding details for debugging
            _logger.LogInformation("Query embedding - Length: {Length}", queryEmbedding.Length);
            _logger.LogInformation("Query embedding - First 10 values: [{Values}]",
                string.Join(", ", queryEmbedding.Take(10).Select(v => v.ToString("F8"))));
            _logger.LogInformation("Query embedding - Last 10 values: [{Values}]",
                string.Join(", ", queryEmbedding.Skip(Math.Max(0, queryEmbedding.Length - 10)).Select(v => v.ToString("F8"))));

            // Calculate similarity scores for documents
            var scoredDocs = new List<(Document doc, double score)>();
            int comparisonCount = 0;
            foreach (var doc in documents)
            {
                // Use the EmbeddingVector property getter which returns the populated field
                var docEmbedding = doc.EmbeddingVector;
                if (docEmbedding == null)
                {
                    _logger.LogWarning("Document {FileName} (ID: {Id}) has NULL embedding vector - skipping", doc.FileName, doc.Id);
                    continue;
                }

                comparisonCount++;
                _logger.LogInformation("--- Comparison #{Count}: Document {FileName} (ID: {Id}) ---", comparisonCount, doc.FileName, doc.Id);
                _logger.LogInformation("  Document embedding - Length: {Length}", docEmbedding.Length);
                _logger.LogInformation("  Document embedding - First 10 values: [{Values}]",
                    string.Join(", ", docEmbedding.Take(10).Select(v => v.ToString("F8"))));
                _logger.LogInformation("  Document embedding - Last 10 values: [{Values}]",
                    string.Join(", ", docEmbedding.Skip(Math.Max(0, docEmbedding.Length - 10)).Select(v => v.ToString("F8"))));

                var similarity = CalculateCosineSimilarity(queryEmbedding, docEmbedding);
                _logger.LogInformation("  Calculated similarity: {Similarity} ({SimilarityPercent:P2})", similarity, similarity);
                
                if (similarity >= minSimilarity)
                {
                    _logger.LogInformation("  ✓ MATCH - Above threshold! Adding to results.");
                    scoredDocs.Add((doc, similarity));
                }
                else
                {
                    _logger.LogInformation("  ✗ NO MATCH - Below threshold of {Threshold:P0}", minSimilarity);
                }
            }

            _logger.LogInformation("Found {Count} documents above similarity threshold {Threshold:P0}", scoredDocs.Count, minSimilarity);
            _logger.LogInformation("=== END SIMILARITY SEARCH DEBUG ===");

            // Get chunks for better precision
            // Query the actual mapped fields: ChunkEmbedding768 or ChunkEmbedding1536
            var chunks = await _context.DocumentChunks
                .Include(c => c.Document)
                .Where(c => c.Document!.OwnerId == userId && (c.ChunkEmbedding768 != null || c.ChunkEmbedding1536 != null))
                .ToListAsync();

            var scoredChunks = new List<(DocumentChunk chunk, double score)>();
            foreach (var chunk in chunks)
            {
                // Use the ChunkEmbedding property getter which returns the populated field
                var chunkEmbedding = chunk.ChunkEmbedding;
                if (chunkEmbedding == null) continue;

                var similarity = CalculateCosineSimilarity(queryEmbedding, chunkEmbedding);
                if (similarity >= minSimilarity)
                {
                    scoredChunks.Add((chunk, similarity));
                }
            }

            // Combine document-level and chunk-level results
            var results = new List<RelevantDocumentResult>();

            // Add chunk-based results (higher priority)
            foreach (var (chunk, score) in scoredChunks.OrderByDescending(x => x.score).Take(topK))
            {
                if (chunk.Document == null) continue;

                results.Add(new RelevantDocumentResult
                {
                    DocumentId = chunk.DocumentId,
                    FileName = chunk.Document.FileName,
                    Category = chunk.Document.ActualCategory,
                    SimilarityScore = score,
                    RelevantChunk = chunk.ChunkText,
                    ChunkIndex = chunk.ChunkIndex
                });
            }

            // Add document-level results if we don't have enough chunks
            if (results.Count < topK)
            {
                var remaining = topK - results.Count;
                var existingDocIds = new HashSet<int>(results.Select(r => r.DocumentId));
                
                foreach (var (doc, score) in scoredDocs.OrderByDescending(x => x.score).Take(remaining))
                {
                    // Avoid duplicates using HashSet for O(1) lookup
                    if (existingDocIds.Contains(doc.Id))
                        continue;

                    results.Add(new RelevantDocumentResult
                    {
                        DocumentId = doc.Id,
                        FileName = doc.FileName,
                        Category = doc.ActualCategory,
                        SimilarityScore = score,
                        ExtractedText = doc.ExtractedText
                    });
                    existingDocIds.Add(doc.Id);
                }
            }

            _logger.LogDebug("Returning {Count} total results", results.Count);
            return results;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error searching documents with embedding for user: {UserId}", userId);
            return new List<RelevantDocumentResult>();
        }
    }

    /// <summary>
    /// Genera una risposta utilizzando Semantic Kernel con contesto dei documenti
    /// Costruisce la chat history includendo system prompt, contesto documenti e cronologia conversazione
    /// </summary>
    /// <param name="query">Query dell'utente</param>
    /// <param name="documentContext">Contesto formattato dei documenti rilevanti</param>
    /// <param name="conversationHistory">Cronologia messaggi della conversazione</param>
    /// <returns>Risposta generata dall'AI basata sul contesto fornito</returns>
    /// <remarks>
    /// Utilizza le seguenti impostazioni:
    /// - MaxTokens: 2000
    /// - Temperature: 0.7 (equilibrio tra creatività e coerenza)
    /// - TopP: 0.9 (nucleus sampling)
    /// </remarks>
    private async Task<string> GenerateAnswerWithSemanticKernelAsync(
        string query,
        string documentContext,
        List<Message> conversationHistory)
    {
        try
        {
            var chatHistory = new ChatHistory();
            chatHistory.AddSystemMessage(CreateSystemPrompt());
            chatHistory.AddSystemMessage($"DOCUMENT CONTEXT:\n{documentContext}");

            // Add conversation history
            foreach (var msg in conversationHistory)
            {
                if (msg.Role == "user")
                    chatHistory.AddUserMessage(msg.Content);
                else if (msg.Role == "assistant")
                    chatHistory.AddAssistantMessage(msg.Content);
            }

            // Add current query
            chatHistory.AddUserMessage(query);

            // Generate response
            var settings = new OpenAIPromptExecutionSettings
            {
                MaxTokens = 2000,
                Temperature = 0.7,
                TopP = 0.9
            };

            var result = await _chatService.GetChatMessageContentAsync(
                chatHistory, settings, _kernel);

            return result.Content ?? "I couldn't generate a response.";
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error generating answer with Semantic Kernel");
            return $"Error generating response: {ex.Message}";
        }
    }

    /// <summary>
    /// Costruisce il contesto formattato dai documenti rilevanti per l'AI
    /// Formatta i documenti in un formato leggibile e strutturato includendo metadati e contenuto
    /// </summary>
    /// <param name="documents">Lista di documenti rilevanti con score di similarità</param>
    /// <returns>Stringa formattata contenente tutti i documenti con metadati e contenuto</returns>
    /// <remarks>
    /// Il formato include per ogni documento:
    /// - Numero documento (per citazioni)
    /// - Nome file
    /// - Categoria
    /// - Score di rilevanza
    /// - Contenuto (chunk rilevante o testo completo)
    /// </remarks>
    private string BuildDocumentContext(List<RelevantDocumentResult> documents)
    {
        var builder = new StringBuilder();
        builder.AppendLine("=== RELEVANT DOCUMENTS ===");
        builder.AppendLine();

        for (int i = 0; i < documents.Count; i++)
        {
            var doc = documents[i];
            builder.AppendLine($"[DOCUMENT {i + 1}]");
            builder.AppendLine($"File: {doc.FileName}");
            builder.AppendLine($"Category: {doc.Category ?? "Uncategorized"}");
            builder.AppendLine($"Relevance: {doc.SimilarityScore:P0}");
            builder.AppendLine();
            builder.AppendLine("Content:");
            builder.AppendLine(doc.RelevantChunk ?? doc.ExtractedText ?? "No content available");
            builder.AppendLine();
            builder.AppendLine("---");
            builder.AppendLine();
        }

        return builder.ToString();
    }

    /// <summary>
    /// Crea il system prompt con istruzioni dettagliate per l'AI
    /// Definisce il ruolo, le regole e il formato di risposta atteso dall'assistente AI
    /// </summary>
    /// <returns>System prompt completo con linee guida per l'AI</returns>
    /// <remarks>
    /// Il prompt istruisce l'AI a:
    /// - Usare solo informazioni dai documenti forniti
    /// - Citare le fonti usando formato [Document N]
    /// - Ammettere quando non ha informazioni sufficienti
    /// - Mantenere un tono professionale e utile
    /// - Essere conciso ma completo
    /// </remarks>
    private string CreateSystemPrompt()
    {
        return @"You are an intelligent document assistant powered by RAG (Retrieval-Augmented Generation).
Your role is to answer questions accurately based on the provided documents.

GUIDELINES:
- Use ONLY information from the provided documents
- Cite sources using [Document N] format
- If information is not in the documents, clearly state that
- Be concise but thorough
- Maintain professional and helpful tone
- If asked about multiple documents, synthesize information appropriately

RESPONSE FORMAT:
1. Provide a direct answer to the question
2. Support with relevant details from documents
3. Cite sources clearly
4. If uncertain, acknowledge limitations";
    }

    /// <summary>
    /// Carica la cronologia della conversazione dal database
    /// Recupera gli ultimi messaggi per mantenere il contesto conversazionale
    /// </summary>
    /// <param name="conversationId">ID della conversazione da caricare</param>
    /// <returns>Lista di messaggi ordinati cronologicamente (massimo 10 messaggi recenti)</returns>
    /// <remarks>
    /// Limita a 10 messaggi per evitare di sovraccaricare il contesto dell'AI
    /// e mantenere tempi di risposta ottimali
    /// </remarks>
    private async Task<List<Message>> LoadConversationHistoryAsync(int? conversationId)
    {
        if (!conversationId.HasValue)
            return new List<Message>();

        try
        {
            return await _context.Messages
                .Where(m => m.ConversationId == conversationId.Value)
                .OrderByDescending(m => m.Timestamp)
                .Take(10)
                .OrderBy(m => m.Timestamp)
                .ToListAsync();
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Error loading conversation history");
            return new List<Message>();
        }
    }

    /// <summary>
    /// Salva la conversazione nel database
    /// Crea una nuova conversazione se necessario o aggiorna quella esistente
    /// </summary>
    /// <param name="conversationId">ID conversazione esistente (null per nuova conversazione)</param>
    /// <param name="userId">ID dell'utente proprietario della conversazione</param>
    /// <param name="query">Domanda dell'utente da salvare</param>
    /// <param name="answer">Risposta dell'AI da salvare</param>
    /// <param name="documentIds">IDs dei documenti referenziati nella risposta</param>
    /// <returns>ID della conversazione (nuovo o esistente)</returns>
    /// <remarks>
    /// Salva sia il messaggio utente che la risposta AI come coppia di messaggi
    /// nella stessa transazione per garantire consistenza
    /// </remarks>
    private async Task<int> SaveConversationAsync(
        int? conversationId,
        string userId,
        string query,
        string answer,
        List<int> documentIds)
    {
        try
        {
            Conversation conversation;

            if (conversationId.HasValue)
            {
                conversation = await _context.Conversations
                    .Include(c => c.Messages)
                    .FirstOrDefaultAsync(c => c.Id == conversationId.Value)
                    ?? throw new InvalidOperationException($"Conversation {conversationId} not found");
            }
            else
            {
                conversation = new Conversation
                {
                    UserId = userId,
                    Title = TruncateText(query, 60),
                    CreatedAt = DateTime.UtcNow,
                    LastMessageAt = DateTime.UtcNow,
                    Messages = new List<Message>()
                };
                _context.Conversations.Add(conversation);
            }

            // Add user message
            conversation.Messages.Add(new Message
            {
                Role = "user",
                Content = query,
                Timestamp = DateTime.UtcNow
            });

            // Add assistant message
            conversation.Messages.Add(new Message
            {
                Role = "assistant",
                Content = answer,
                ReferencedDocumentIds = documentIds,
                Timestamp = DateTime.UtcNow
            });

            conversation.LastMessageAt = DateTime.UtcNow;

            await _context.SaveChangesAsync();

            return conversation.Id;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error saving conversation");
            return conversationId ?? 0;
        }
    }

    /// <summary>
    /// Calcola la similarità coseno tra due vettori
    /// Misura l'angolo tra due vettori nello spazio multidimensionale
    /// </summary>
    /// <param name="vector1">Primo vettore embedding</param>
    /// <param name="vector2">Secondo vettore embedding</param>
    /// <returns>
    /// Score di similarità tra 0 e 1, dove:
    /// - 1 = vettori identici o molto simili
    /// - 0 = vettori ortogonali (nessuna similarità)
    /// - Valori vicini a 1 indicano alta similarità semantica
    /// </returns>
    /// <remarks>
    /// Formula: cosine_similarity = (A · B) / (||A|| * ||B||)
    /// dove A · B è il prodotto scalare e ||A|| è la norma euclidea
    /// </remarks>
    private double CalculateCosineSimilarity(float[] vector1, float[] vector2)
    {
        if (vector1.Length != vector2.Length)
            return 0;

        double dotProduct = 0;
        double magnitude1 = 0;
        double magnitude2 = 0;

        for (int i = 0; i < vector1.Length; i++)
        {
            dotProduct += vector1[i] * vector2[i];
            magnitude1 += vector1[i] * vector1[i];
            magnitude2 += vector2[i] * vector2[i];
        }

        magnitude1 = Math.Sqrt(magnitude1);
        magnitude2 = Math.Sqrt(magnitude2);

        if (magnitude1 == 0 || magnitude2 == 0)
            return 0;

        return dotProduct / (magnitude1 * magnitude2);
    }

    /// <summary>
    /// Tronca il testo alla lunghezza massima specificata
    /// Aggiunge "..." alla fine se il testo supera la lunghezza massima
    /// </summary>
    /// <param name="text">Testo da troncare</param>
    /// <param name="maxLength">Lunghezza massima desiderata</param>
    /// <returns>Testo troncato con ellipsis se necessario</returns>
    private string TruncateText(string text, int maxLength)
    {
        if (string.IsNullOrEmpty(text) || text.Length <= maxLength)
            return text ?? string.Empty;

        return text.Substring(0, maxLength - 3) + "...";
    }
}
